{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo: PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_originals = pd.DataFrame({\"A\": [102,104,101,93,100], \"B\": [96,87,62,68,77]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padronizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.matrix(var_originals);x\n",
    "#x = np.asarray(x);x\n",
    "\n",
    "#Padronizando para media 0 e variancia 1\n",
    "z_score_A = (var_originals-var_originals.mean())/var_originals.std(axis=0)\n",
    "#z_score_A\n",
    "#Padronizando para media qualquer e variancia 1\n",
    "z_score_B = var_originals/var_originals.std(axis=0)\n",
    "#z_score_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = z_score_B.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo os Autovetores e Autovalores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando a matriz de correlacao do tipo pandas no tipo matrix\n",
    "data_corr = np.asmatrix(correlation);data_corr\n",
    "#Obtendo os Autovalores e autovetores\n",
    "autovalues, autovectors = np.linalg.eig(data_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proporçao da variancia total explicada pelo i-esimo componente principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77278095, 0.22721905])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_expl = autovalues/sum(autovalues);var_expl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porcentagem acumulada de variancia dos Yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 77.27809539, 100.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_var_expl = np.cumsum(var_expl)*100; cum_var_expl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo os scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Componentes 1</th>\n",
       "      <th>Componentes 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.159376</td>\n",
       "      <td>-12.322918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.036354</td>\n",
       "      <td>-13.122063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.248472</td>\n",
       "      <td>-13.895760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.203615</td>\n",
       "      <td>-12.236124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.847915</td>\n",
       "      <td>-12.958256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Componentes 1  Componentes 2\n",
       "0      22.159376     -12.322918\n",
       "1      22.036354     -13.122063\n",
       "2      20.248472     -13.895760\n",
       "3      19.203615     -12.236124\n",
       "4      20.847915     -12.958256"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_met_matricial = np.matmul(autovectors.T, np.matrix(z_score_B).T)\n",
    "#P = autovectors.T.dot(z_score_B.T)\n",
    "#print(P.T)\n",
    "scores_met_matricial = pd.DataFrame(scores_met_matricial.T, columns=[f\"Componentes {i+1}\" for i in range(len(autovectors))])\n",
    "scores_met_matricial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo as variáveis originais pela transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.382664</td>\n",
       "      <td>6.955426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.860755</td>\n",
       "      <td>6.303355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.143618</td>\n",
       "      <td>4.492046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.231252</td>\n",
       "      <td>4.926760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.904572</td>\n",
       "      <td>5.578831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A         B\n",
       "0  24.382664  6.955426\n",
       "1  24.860755  6.303355\n",
       "2  24.143618  4.492046\n",
       "3  22.231252  4.926760\n",
       "4  23.904572  5.578831"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_score_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Componentes 1  Componentes 2\n",
      "0      22.159376     -12.322918\n",
      "1      22.036354     -13.122063\n",
      "2      20.248472     -13.895760\n",
      "3      19.203615     -12.236124\n",
      "4      20.847915     -12.958256\n",
      "[[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "print(scores_met_matricial)\n",
    "print(autovectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores pela padronização normal (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.26022964,  0.58410623],\n",
       "        [ 1.13720737, -0.21503944],\n",
       "        [-0.65067398, -0.98873568],\n",
       "        [-1.69553148,  0.67090044],\n",
       "        [-0.05123155, -0.05123155]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_met_matricial_normal_padrao = np.dot(z_score_A, autovectors)\n",
    "scores_met_matricial_normal_padrao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores reconstruídos para a normal (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[100.47809144,  79.3041424 ],\n",
       "        [100.95618289,  78.6520712 ],\n",
       "        [100.23904572,  76.84076231],\n",
       "        [ 98.32667995,  77.27547644],\n",
       "        [100.        ,  77.92754764]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(scores_met_matricial_normal_padrao, autovectors.T) + var_originals.mean().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo por meio do pacote Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_ufrj = PCA(n_components=2)\n",
    "pca_ufrj.fit(z_score_B)\n",
    "scores = pca_ufrj.transform(z_score_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  19.6619315 , -134.35585894],\n",
       "       [  11.88375691, -129.40611147],\n",
       "       [  -3.67259228, -109.6071216 ],\n",
       "       [   6.22690266, -108.19290803],\n",
       "       [   7.64111622, -119.50661653]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_ufrj.inverse_transform(z_score_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores dos componentes principais:\n",
      "   Componente 1  Componente 2\n",
      "0     18.073738      1.157581\n",
      "1      9.558063     -2.375589\n",
      "2    -15.582957     -3.764497\n",
      "3    -11.064051      5.156237\n",
      "4     -0.984793     -0.173731\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Criar o DataFrame com os dados\n",
    "var_originals = pd.DataFrame({\"A\": [102, 104, 101, 93, 100], \"B\": [96, 87, 62, 68, 77]})\n",
    "\n",
    "# Instanciar a classe PCA\n",
    "n_components = 2  # Número de componentes principais desejados\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Ajustar o modelo aos dados e obter os scores dos componentes principais\n",
    "principal_components = pca.fit_transform(var_originals)\n",
    "\n",
    "# Converter os scores dos componentes principais em um DataFrame\n",
    "principal_components_df = pd.DataFrame(data=principal_components, columns=[f\"Componente {i+1}\" for i in range(n_components)])\n",
    "\n",
    "print(\"Scores dos componentes principais:\")\n",
    "print(principal_components_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados diferem do metodo manual devido a diferenças em como calcular as matrizes, os autovetores vsão obtidos com o sinal trocado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores dos componentes principais:\n",
      "   Componente 1  Componente 2\n",
      "0     -1.260230     -0.584106\n",
      "1     -1.137207      0.215039\n",
      "2      0.650674      0.988736\n",
      "3      1.695531     -0.670900\n",
      "4      0.051232      0.051232\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Criar o DataFrame com os dados\n",
    "var_originals = pd.DataFrame({\"A\": [102, 104, 101, 93, 100], \"B\": [96, 87, 62, 68, 77]})\n",
    "\n",
    "z_score_B = var_originals/var_originals.std(axis=0)\n",
    "\n",
    "# Padronizar os dados\n",
    "#scaler = StandardScaler()\n",
    "#var_standardized = scaler.fit_transform(var_originals)\n",
    "var_standardized=z_score_B\n",
    "# Instanciar a classe PCA\n",
    "n_components = 2  # Número de componentes principais desejados\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized')\n",
    "\n",
    "# Ajustar o modelo aos dados padronizados e obter os scores dos componentes principais\n",
    "pca_1 = pca.fit(var_standardized)\n",
    "principal_components = pca_1.transform(var_standardized)\n",
    "\n",
    "# Converter os scores dos componentes principais em um DataFrame\n",
    "principal_components_df = pd.DataFrame(data=principal_components, columns=[f\"Componente {i+1}\" for i in range(n_components)])\n",
    "\n",
    "print(\"Scores dos componentes principais:\")\n",
    "print(principal_components_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.26022964  0.58410623]\n",
      " [ 1.13720737 -0.21503944]\n",
      " [-0.65067398 -0.98873568]\n",
      " [-1.69553148  0.67090044]\n",
      " [-0.05123155 -0.05123155]]\n",
      "Autovetores:\n",
      "[[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n",
      "Valores estimados (reconstruídos):\n",
      "            A          B\n",
      "0  100.478091  79.304142\n",
      "1  100.956183  78.652071\n",
      "2  100.239046  76.840762\n",
      "3   98.326680  77.275476\n",
      "4  100.000000  77.927548\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Criar o DataFrame com os dados\n",
    "var_originals = pd.DataFrame({\"A\": [102, 104, 101, 93, 100], \"B\": [96, 87, 62, 68, 77]})\n",
    "\n",
    "# Padronizar os dados manualmente\n",
    "var_standardized = (var_originals - var_originals.mean()) / var_originals.std()\n",
    "\n",
    "# Calcular a matriz de covariância\n",
    "covariance_matrix = np.cov(var_standardized, rowvar=False)\n",
    "\n",
    "# Calcular os autovetores e autovalores\n",
    "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "# Ordenar os autovetores pelos autovalores em ordem decrescente\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvectors_sorted = eigenvectors[:, sorted_indices]\n",
    "\n",
    "# Escolher o número de componentes principais desejados\n",
    "n_components = 2\n",
    "selected_eigenvectors = eigenvectors_sorted[:, :n_components]\n",
    "\n",
    "# Calcular os scores dos componentes principais\n",
    "principal_components = np.dot(var_standardized, selected_eigenvectors)\n",
    "\n",
    "# Calcular os valores estimados (reconstruídos)\n",
    "estimated_values = np.dot(principal_components, selected_eigenvectors.T) + var_originals.mean().values\n",
    "print(principal_components)\n",
    "print(\"Autovetores:\")\n",
    "print(selected_eigenvectors)\n",
    "\n",
    "# Converter os valores estimados em um DataFrame\n",
    "estimated_values_df = pd.DataFrame(data=estimated_values, columns=var_originals.columns)\n",
    "\n",
    "print(\"Valores estimados (reconstruídos):\")\n",
    "print(estimated_values_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
